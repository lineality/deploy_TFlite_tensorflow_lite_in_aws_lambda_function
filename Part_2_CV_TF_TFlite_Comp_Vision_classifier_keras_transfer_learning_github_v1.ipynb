{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*Adapted from chapter 3 in the excellent book: Practical Deep Learning*\n",
        "\n",
        "https://www.practicaldeeplearning.ai/\n",
        "\n",
        "*Highly recommended*"
      ],
      "metadata": {
        "id": "uJl-1GD3A_EY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Flow, Computer Vision, Image Classifer, Colab-Notebook\n",
        "\n",
        "### Required (to make a model):\n",
        "two zipped folders:\n",
        "- train \n",
        "- val\n",
        "\n",
        "In each of those folders (train and val) is another pair of (or set of) folders, one for each classification-class (e.g. \"apples\" and \"oranges\"). \n",
        "\n",
        "Each of those folders contains some portion of the overall set of training images. E.g. for an 80/20 split train/validate: put 80% of pics per classificaiton-class in that folder, and 20% in the other.\n",
        "\n",
        "For upload to colab, the folders should be zipped, as train.zip, val.zip. This notebook is set up to unzip those.\n",
        "\n",
        "To try out whether the model works given an input picture:\n",
        "\n",
        "### This Requires (to test on a picture):\n",
        "a picture (or one for each classification-class, as you like it.) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Required Naming:\n",
        "The formatting of the naming of the images may need to be standardized:\n",
        "```\n",
        "image_class.number.filetype\n",
        "```\n",
        "e.g.\n",
        "```\n",
        "dog.123.jpg\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## Colab file contents will look something like this (after the train and val folders are unzipped, and with two test-it-out images):\n",
        "```\n",
        "orange.1.jpeg\t  sample_data  train.zip  val.zip\n",
        "apple.1.jpg  train        val\n",
        "```\n",
        "Note: The sample data folder is a default of google-colab. \n",
        "\n",
        "\n",
        "### Reguired: to use the ai model that you make later:\n",
        "Make sure you donwload it from the colab and save it. "
      ],
      "metadata": {
        "id": "O5ahnxrXVi_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Code: Script to add the classification-class name to a folder full of numbered image files.\n",
        "\n",
        "Taking 1000 pictures is easy! Manually renaming them all is less fun.\n",
        "\n",
        "Here is a python script to add the classifican-class-name to your images. \n",
        "\n",
        ":tada: !"
      ],
      "metadata": {
        "id": "cCh_fliQOQ0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Code to rename all files in a directory\n",
        "with the name of the directory appended \n",
        "to the file name\n",
        "with a period between:\n",
        "\n",
        "e.g.\n",
        "folder_name.original_name.suffix\n",
        "\n",
        "e.g.\n",
        "whalepics.231.jpg\n",
        "\"\"\"\n",
        "\n",
        "# import your vanilla libraries (no pip installs needed)\n",
        "import os \n",
        "import glob\n",
        "\n",
        "# get the folder name (whole current working directory path)\n",
        "full_path = os.getcwd()\n",
        "\n",
        "\"\"\"\n",
        "reduce full name to just the name of this directory\n",
        "split the name on \"/\" and slice off just the last name [-1]\n",
        "\"\"\"\n",
        "this_directory = full_path.split(\"/\")[-1]\n",
        "\n",
        "\"\"\"\n",
        "iterate through a list of folder contents obtained with glob\n",
        "'*' is a wildcard to get all files, but you can substitute\n",
        "in a specific suffix for a file type\n",
        "e.g. glob.glob('*.jpg')\n",
        "\"\"\"\n",
        "for this_file_name in glob.glob('*.*'):\n",
        "\n",
        "    # optional print old name\n",
        "    print(\"old = \", this_file_name)\n",
        "    \n",
        "    # make the new name string\t\n",
        "    new_name = this_directory + \".\" + this_file_name \n",
        "    \n",
        "    # change old name to new neame\n",
        "    os.rename(this_file_name, new_name)\n",
        "    \n",
        "    # optional print the new name\n",
        "    print(\"new = \", new_name, \"\\n\")\n"
      ],
      "metadata": {
        "id": "xdUxgwXEOQ_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unzip your two folders/directories:\n",
        "- train\n",
        "- val"
      ],
      "metadata": {
        "id": "OVooz7THWOp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip training data folder (of pics)\n",
        "!unzip train.zip"
      ],
      "metadata": {
        "id": "hF-_GqmbWKmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip validation data folder (of pics)\n",
        "!unzip val.zip"
      ],
      "metadata": {
        "id": "n11yKdtNWMRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect directory\n",
        "!ls"
      ],
      "metadata": {
        "id": "uIm0U_jhCePz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkVkxKFrMLT6"
      },
      "outputs": [],
      "source": [
        "# import libraries and packages\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input\n",
        "import math\n",
        "\n",
        " # but wait, there's more!\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jPHPe1cMLT6"
      },
      "source": [
        "Let's place all the configurations up-front. These can be modified in the future based on the dataset of your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nKjQwPiMLT6"
      },
      "outputs": [],
      "source": [
        "\n",
        "#################\n",
        "# Configurations\n",
        "#################\n",
        "\n",
        "TRAIN_DATA_DIR = 'train/'\n",
        "VALIDATION_DATA_DIR = 'val/'\n",
        "TRAIN_SAMPLES = 500\n",
        "VALIDATION_SAMPLES = 500\n",
        "NUM_CLASSES = 2\n",
        "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmentation\n",
        "\n",
        "TODO: \n",
        "\n",
        "Q: Optimal image rotation?"
      ],
      "metadata": {
        "id": "MwthZS7kYamz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbwMihpMMLT6"
      },
      "outputs": [],
      "source": [
        "\n",
        "###########################################\n",
        "# set up your preprocessing data generator\n",
        "###########################################\n",
        "\n",
        "# set up for training data\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                                   rotation_range=20,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   zoom_range=0.2)\n",
        "\n",
        "# set up for validation data\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3Fswf5lMLT6"
      },
      "outputs": [],
      "source": [
        "train_generator = train_datagen.flow_from_directory(TRAIN_DATA_DIR,\n",
        "                                                    target_size=(IMG_WIDTH,\n",
        "                                                                 IMG_HEIGHT),\n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    shuffle=True,\n",
        "                                                    seed=12345,\n",
        "                                                    class_mode='categorical')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    VALIDATION_DATA_DIR,\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hy84NUcMLT7"
      },
      "source": [
        "## Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PweTPSXTMLT7"
      },
      "outputs": [],
      "source": [
        "def model_maker():\n",
        "    base_model = MobileNet(include_top=False,\n",
        "                           input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "    for layer in base_model.layers[:]:\n",
        "        layer.trainable = False\n",
        "    input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "    custom_model = base_model(input)\n",
        "    custom_model = GlobalAveragePooling2D()(custom_model)\n",
        "    custom_model = Dense(64, activation='relu')(custom_model)\n",
        "    custom_model = Dropout(0.5)(custom_model)\n",
        "    predictions = Dense(NUM_CLASSES, activation='softmax')(custom_model)\n",
        "    return Model(inputs=input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# .fit"
      ],
      "metadata": {
        "id": "EQHBp2EqWmE7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "j0isPNh7MLT8"
      },
      "outputs": [],
      "source": [
        "model = model_maker()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "              metrics=['acc'])\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=math.ceil(float(TRAIN_SAMPLES) / BATCH_SIZE),\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=math.ceil(float(VALIDATION_SAMPLES) / BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the Model\n",
        "\n",
        "# **You need to manually download this from Colab**\n",
        "\n"
      ],
      "metadata": {
        "id": "ABQiPqHpWynD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "U6dbP0NVD5N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# .predict"
      ],
      "metadata": {
        "id": "Pf-RZfjSWriS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qYNYjHhMLT8"
      },
      "source": [
        "## Model Prediction (from your saved model)\n",
        "\n",
        "Now that you have a trained model, you might eventually want to use it later for your application. We can now load this model anytime and classify an image. The Keras function `load_model`, as the name suggests loads the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E-MPv6jMLT8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Save your model in .h5 format (one file, not a directory)\n",
        "model.save('model.h5')\n",
        "\n",
        "# Load the .h5 model file and test it\n",
        "model = load_model('model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWGEK5XzMLT9"
      },
      "source": [
        "Now let’s try loading our original sample images and see what results we get."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "d3hEesLprg8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test a picture"
      ],
      "metadata": {
        "id": "0yqNECEODRS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select test image\n",
        "img_path = 'orange.1.jpeg'\n",
        "\n",
        "# Preprocess the image\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "expanded_img_array = np.expand_dims(img_array, axis=0)\n",
        "preprocessed_img = expanded_img_array / 255.  \n",
        "\n",
        "# predict\n",
        "prediction = model.predict(preprocessed_img)\n",
        "\n",
        "# print output\n",
        "print(prediction)\n",
        "print(validation_generator.class_indices)"
      ],
      "metadata": {
        "id": "02DfDpifDQpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test an \"apple\" picture"
      ],
      "metadata": {
        "id": "CMW0pICeDTib"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0g9x50J7MLT9"
      },
      "outputs": [],
      "source": [
        "# select test image\n",
        "img_path = 'apple.1.jpg'\n",
        "\n",
        "# Preprocess the image\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "expanded_img_array = np.expand_dims(img_array, axis=0)\n",
        "preprocessed_img = expanded_img_array / 255.  \n",
        "\n",
        "# predict\n",
        "prediction = model.predict(preprocessed_img)\n",
        "\n",
        "# print output\n",
        "print(prediction)\n",
        "print(validation_generator.class_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Tensorflow Model (not yet .tflite)"
      ],
      "metadata": {
        "id": "btv6YfahZo1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "export_dir = 'saved_model/'\n",
        "tf.saved_model.save(model, export_dir)\n",
        "\n",
        "# inspect\n",
        "!ls"
      ],
      "metadata": {
        "id": "-GiHemRLZo-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make .ftlite Model (Convert Tensorflow Model to .tflite)"
      ],
      "metadata": {
        "id": "7MHDEWSgZyRJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make 'model.tflite'\n",
        "\n",
        "Note: the suffix is fixed, but you can change\n",
        "the first part of the name,\n",
        "but the sample code here assumes \"model.tflite\"\n",
        "\n",
        "\n",
        "```\n",
        "YOUR_CHOICE_OF_NAME.tflite\n",
        "```"
      ],
      "metadata": {
        "id": "hNODO35R6Obx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#########################################\n",
        "# Make Your TFlite Version of your Model\n",
        "#########################################\n",
        "# See: https://www.tensorflow.org/lite/convert/\n",
        "\n",
        "# Save the TF model as directory\n",
        "TF_model_directory = 'saved_model/'\n",
        "tf.saved_model.save(model, TF_model_directory)\n",
        "\n",
        "# Convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model( TF_model_directory ) # path to the SavedModel directory\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "# inspect\n",
        "!ls"
      ],
      "metadata": {
        "id": "JcfqMGzBXiHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# inspect\n",
        "!ls"
      ],
      "metadata": {
        "id": "QQCbuNKlZyXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now your model.tflite file is ready to be deployed."
      ],
      "metadata": {
        "id": "zQoDxTIkrI1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# .tflite model \n",
        "\n",
        "This code is not the same as the tflite code."
      ],
      "metadata": {
        "id": "krZl6r8Pa7U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "\n",
        "# select test image\n",
        "img_path = 'orange.1.jpg'\n",
        "\n",
        "# Preprocess the image\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "expanded_img_array = np.expand_dims(img_array, axis=0)\n",
        "preprocessed_img = expanded_img_array / 255.  \n",
        "\n",
        "# set: input_data = preprocessed image\n",
        "input_data = preprocessed_img\n",
        "    \n",
        "# y: using model, producing y from X\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "interpreter.invoke()\n",
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "# inspection\n",
        "print(\"Output is probability of identification.\")\n",
        "print(tflite_results)\n"
      ],
      "metadata": {
        "id": "ksg6bIKKbI-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd9416ff-976c-44bc-c356-0e01bca4d273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output is probability of identification.\n",
            "y = [[0.5410198  0.45898017]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Part 2: CV-TF_TFlite_Comp_Vision_classifier_keras_transfer_learning_github_v1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}